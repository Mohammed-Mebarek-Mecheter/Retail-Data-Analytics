{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T21:47:30.229931100Z",
     "start_time": "2023-09-19T21:47:30.223653200Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445f8fcdebea51a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T21:47:36.042215900Z",
     "start_time": "2023-09-19T21:47:34.361667100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load X_train and y_train\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv', header=None)  # Use header=None to read a single-column CSV\n",
    "\n",
    "# Load X_test and y_test\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7493f1369ddfdb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T21:47:37.479318500Z",
     "start_time": "2023-09-19T21:47:37.474320800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',  # Use squared error as the objective function for regression\n",
    "    learning_rate=0.1,             # Learning rate (you can tune this)\n",
    "    n_estimators=100,             # Number of trees in the ensemble (you can tune this)\n",
    "    max_depth=6,                   # Maximum depth of each tree (you can tune this)\n",
    "    random_state=42                # Set a random seed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbae90c035141ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T21:47:43.052875400Z",
     "start_time": "2023-09-19T21:47:40.301795800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [337256, 337257]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m100\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m300\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m4\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m8\u001b[39m]\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      7\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mxgb_model, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      9\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:782\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_refit_for_multimetric(scorers)\n\u001b[0;32m    780\u001b[0m     refit_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit\n\u001b[1;32m--> 782\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    783\u001b[0m fit_params \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m    785\u001b[0m cv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n",
      "File \u001b[1;32mc:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39mresult)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [337256, 337257]"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1088f1f2eea2e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T21:48:50.291256100Z",
     "start_time": "2023-09-19T21:48:50.256510600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (337256, 19)\n",
      "y_train shape: (337257, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ad5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.iloc[:-1]  # Remove the last row to match the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43d119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (337256, 19)\n",
      "y_train shape: (337256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6971e472",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n135 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n    return DMatrix(**kwargs, nthread=self.n_jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 957, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 404, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n                                         ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 378, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 270, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:IsHoliday.1: object\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m100\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m300\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m4\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m8\u001b[39m]\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      7\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mxgb_model, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      9\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_score)\n\u001b[0;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n135 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n    return DMatrix(**kwargs, nthread=self.n_jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 957, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 404, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n                                         ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 378, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"c:\\Users\\Mebarek\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 270, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:IsHoliday.1: object\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163422d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
