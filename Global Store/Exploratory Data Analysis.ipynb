{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:08:13.000737Z",
     "start_time": "2023-09-19T16:08:12.066544900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Read the datasets\n",
    "stores_df = pd.read_csv('data/stores data-set.csv')\n",
    "features_df = pd.read_csv('data/Features data set.csv')\n",
    "sales_df = pd.read_csv('data/sales data-set.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:23:34.992637800Z",
     "start_time": "2023-09-19T16:23:34.655136500Z"
    }
   },
   "id": "ed235a5da7956e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  Unique stores in the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f01a42e891e3b1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stores: 45\n"
     ]
    }
   ],
   "source": [
    "# Use the nunique() function to count unique values in the 'Store' column\n",
    "unique_stores = stores_df['Store'].nunique()\n",
    "\n",
    "print(\"Number of unique stores:\", unique_stores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:08:35.333578400Z",
     "start_time": "2023-09-19T16:08:35.291427800Z"
    }
   },
   "id": "e4e537035f6041a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  The different types of stores, and how many stores belong to each type"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85d21ac8efd0d690"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Types and Their Counts:\n",
      "A    22\n",
      "B    17\n",
      "C     6\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use the value_counts() function to count the occurrences of each store type\n",
    "store_type_counts = stores_df['Type'].value_counts()\n",
    "\n",
    "print(\"Store Types and Their Counts:\")\n",
    "print(store_type_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:11:59.904630300Z",
     "start_time": "2023-09-19T16:11:59.820539900Z"
    }
   },
   "id": "243901b8347c1726"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  The average size of stores in each type"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7a80ce9b9861d72"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Size of Stores in Each Type:\n",
      "Type\n",
      "A    177247.727273\n",
      "B    101190.705882\n",
      "C     40541.666667\n",
      "Name: Size, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group the data by store type and calculate the average size for each group\n",
    "average_size_by_type = stores_df.groupby('Type')['Size'].mean()\n",
    "\n",
    "print(\"Average Size of Stores in Each Type:\")\n",
    "print(average_size_by_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:14:11.438279700Z",
     "start_time": "2023-09-19T16:14:11.391802Z"
    }
   },
   "id": "6c7a9bcc8503d8a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  The range of dates in the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75c9f079de2130d8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range in the Features Dataset:\n",
      "Minimum Date: 2010-01-10 00:00:00\n",
      "Maximum Date: 2013-12-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime format for date range analysis\n",
    "features_df['Date'] = pd.to_datetime(features_df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Find the minimum and maximum dates in the dataset\n",
    "min_date = features_df['Date'].min()\n",
    "max_date = features_df['Date'].max()\n",
    "\n",
    "print(\"Date Range in the Features Dataset:\")\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:19:03.935855100Z",
     "start_time": "2023-09-19T16:19:03.897588900Z"
    }
   },
   "id": "e9230574c97b511a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  Unique stores in the Features dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d0fe608992ae9f9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stores in the Features dataset: 45\n"
     ]
    }
   ],
   "source": [
    "# Use the nunique() function to count unique values in the 'Store' column\n",
    "unique_stores_in_features = features_df['Store'].nunique()\n",
    "\n",
    "print(\"Number of unique stores in the Features dataset:\", unique_stores_in_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:19:58.940150800Z",
     "start_time": "2023-09-19T16:19:58.895982100Z"
    }
   },
   "id": "36c31caea2cc03b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  Missing values in temperature, fuel price, CPI, or unemployment columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80516f1d72c3074d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Columns:\n",
      "Temperature       0\n",
      "Fuel_Price        0\n",
      "CPI             585\n",
      "Unemployment    585\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the specified columns\n",
    "missing_values = features_df[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']].isnull().sum()\n",
    "\n",
    "print(\"Missing Values in Columns:\")\n",
    "print(missing_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:20:42.691452700Z",
     "start_time": "2023-09-19T16:20:42.569930600Z"
    }
   },
   "id": "ca0ce4d9f55c04db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####    The distribution of IsHoliday values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c6c176889a64069"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of IsHoliday Values:\n",
      "False    7605\n",
      "True      585\n",
      "Name: IsHoliday, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each 'IsHoliday' value\n",
    "holiday_distribution = features_df['IsHoliday'].value_counts()\n",
    "\n",
    "print(\"Distribution of IsHoliday Values:\")\n",
    "print(holiday_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:21:46.201729300Z",
     "start_time": "2023-09-19T16:21:46.153331500Z"
    }
   },
   "id": "79e30b70087924b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####    Unique departments in the sales dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b22650d3abe8c6eb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique departments in the Sales dataset: 81\n"
     ]
    }
   ],
   "source": [
    "# Use the nunique() function to count unique values in the 'Dept' column\n",
    "unique_departments = sales_df['Dept'].nunique()\n",
    "\n",
    "print(\"Number of unique departments in the Sales dataset:\", unique_departments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:23:53.859757900Z",
     "start_time": "2023-09-19T16:23:53.820994200Z"
    }
   },
   "id": "855682d23e169ac8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####    The range of dates for which sales data is available"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9438d0c9242cd5d1"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range for Sales Data:\n",
      "Minimum Date: 2010-02-05 00:00:00\n",
      "Maximum Date: 2012-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime format for date range analysis\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Find the minimum and maximum dates in the dataset\n",
    "min_sales_date = sales_df['Date'].min()\n",
    "max_sales_date = sales_df['Date'].max()\n",
    "\n",
    "print(\"Date Range for Sales Data:\")\n",
    "print(\"Minimum Date:\", min_sales_date)\n",
    "print(\"Maximum Date:\", max_sales_date)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:26:23.347234100Z",
     "start_time": "2023-09-19T16:26:23.149204800Z"
    }
   },
   "id": "c88b70abdc97f0ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####    Missing values in Weekly_Sales"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "606157fa88de7639"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Weekly_Sales: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the 'Weekly_Sales' column\n",
    "missing_values = sales_df['Weekly_Sales'].isnull().sum()\n",
    "\n",
    "print(\"Number of missing values in Weekly_Sales:\", missing_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:27:12.730190200Z",
     "start_time": "2023-09-19T16:27:12.684134800Z"
    }
   },
   "id": "b7d5a9d04dadcbde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####  The distribution of IsHoliday values in the sales dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ffea18dffe77a8a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of IsHoliday Values in the Sales dataset:\n",
      "False    391909\n",
      "True      29661\n",
      "Name: IsHoliday, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each 'IsHoliday' value\n",
    "holiday_distribution = sales_df['IsHoliday'].value_counts()\n",
    "\n",
    "print(\"Distribution of IsHoliday Values in the Sales dataset:\")\n",
    "print(holiday_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T16:28:12.599973200Z",
     "start_time": "2023-09-19T16:28:12.540146400Z"
    }
   },
   "id": "3d3a91860baed417"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
